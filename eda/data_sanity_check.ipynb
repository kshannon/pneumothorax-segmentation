{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path defs\n",
    "train_path = '../data/dicom-images-train/'\n",
    "test_path = '../data/dicom-images-test/'\n",
    "train_dicom_names = '../data/train-dicom-names.csv'\n",
    "test_dicom_names = '../data/test-dicom-names.csv'\n",
    "annot_csv = '../data/train-rle.csv'\n",
    "sample_data = '../data/sample images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Data\n",
    "\n",
    "Issue one user had, look for these issues:\n",
    "> I was able to download all train data (10712 images) - all I had to use sleep(0.025) before two api calls for each study_uid in download_images.py script. The remaining issue is that there is 37 images in train set which don't have annotations. Two options there - drop them from training, or assume its rle-encoding is \"-1\"\"\n",
    "\n",
    "All dicom images are placed within two folders. E.g.\n",
    "- ../data/dicom-images-test/\n",
    "- 1.2.276.0.7230010.3.1.2.8323329.6769.1517875200.68560/ <-- folder 1 of many\n",
    "- 1.2.276.0.7230010.3.1.3.8323329.6769.1517875200.68559/ <-- folder 2 of one\n",
    "- 1.2.276.0.7230010.3.1.4.8323329.6769.1517875200.68561.dcm <-- single dicom image\n",
    "\n",
    "pipe recursive file count to wc: ```find . -type f | wc -l``` Get's us the number of images\n",
    "\n",
    "Now we need the name of all the dicom images ```find ../data/dicom-images-train/ -type f -printf \"%f\\n\" | paste -sd ',' >> ../data/train-dicom-names``` We will use this to cross ref the annotations csv and also check for duplicate data.\n",
    "\n",
    "\n",
    "Train Imgs: 10712  -  Annotations: 11582 (8296 = -1, 3286 = disorder annotated) roughly 3:1\n",
    "\n",
    "Test Imgs: 1377  -  Annotations: No .dcm images are present in the annotation file.\n",
    "\n",
    "Duplicate Dicom Imgs: No\n",
    "\n",
    "##### ISSUE: 37 Dicom images are not accounted for in the annotation list. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train-dicom-names.csv: count assumption valid, no duplicates!\n",
      "../data/test-dicom-names.csv: count assumption valid, no duplicates!\n"
     ]
    }
   ],
   "source": [
    "def dicom_count_checker(path, assumed_count):\n",
    "    '''Assure our dicom counts are correct, no duplicates, and we downloaded the correct amount of data'''\n",
    "    counted_imgs = 0\n",
    "    data_set = set()\n",
    "    with open(path, 'r') as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip('\\n') #chomp chomp\n",
    "            counted_imgs += 1\n",
    "            data_set.add(line)\n",
    "    assert counted_imgs == assumed_count & len(data_set) == assumed_count\n",
    "    print(path + ': count assumption valid, no duplicates!')\n",
    "    return data_set\n",
    "\n",
    "train_names = dicom_count_checker(train_dicom_names, 10712)\n",
    "test_names = dicom_count_checker(test_dicom_names, 1377)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data leakage\n"
     ]
    }
   ],
   "source": [
    "# ensure no data leakage between train/test. These should be same len \n",
    "# between set union and non-concat len addition\n",
    "assert (len(train_names) + len(test_names)) == len(train_names.union(test_names))\n",
    "print('no data leakage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total annotations:  11582\n",
      "total rows w/o annotations:  8296\n",
      "total unique annotations:  10675\n"
     ]
    }
   ],
   "source": [
    "# strip out dicom file names from annotated list\n",
    "# count the number of annotated files with no disoder present\n",
    "count = 0\n",
    "count_no_annot = 0\n",
    "unique_annotations = set()\n",
    "\n",
    "with open(annot_csv, 'r') as infile:\n",
    "    next(infile)\n",
    "    for line in infile:\n",
    "        count += 1\n",
    "        cols = line.split(',')\n",
    "        cols[1] = cols[1].strip('\\n').lstrip() #chomp\n",
    "        if cols[1] == '-1':\n",
    "            count_no_annot += 1\n",
    "        unique_annotations.add(cols[0]+'.dcm')\n",
    "\n",
    "print('total annotations: ', count)\n",
    "print('total rows w/o annotations: ',count_no_annot)\n",
    "print('total unique annotations: ',len(unique_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no annotated test files... yay!\n"
     ]
    }
   ],
   "source": [
    "# take the disjoint of the annotated file names with the test file names. Should return an empty set.\n",
    "assert unique_annotations.isdisjoint(test_names)\n",
    "print('no annotated test files... yay!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10712\n",
      "10675\n"
     ]
    }
   ],
   "source": [
    "# Here is the issue... not all training images are annotated...\n",
    "print(len(train_names))\n",
    "print(len(unique_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1.2.276.0.7230010.3.1.4.8323329.10231.1517875222.737143.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.10362.1517875223.377845.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.10407.1517875223.567351.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.10599.1517875224.488727.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.1068.1517875166.144255.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.11104.1517875231.169401.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.11215.1517875231.757436.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.11557.1517875233.601090.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.11566.1517875233.640521.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.11577.1517875233.694347.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.11584.1517875233.731531.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.12062.1517875237.179186.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.13378.1517875244.961609.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.13415.1517875245.218707.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.13620.1517875246.884737.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.14557.1517875252.690062.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.2083.1517875171.71387.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.2187.1517875171.557615.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.2309.1517875172.75133.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.2563.1517875173.431928.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.2630.1517875173.773726.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.3089.1517875176.36192.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.31801.1517875156.929061.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.32302.1517875159.778024.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.32688.1517875161.809571.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.3321.1517875177.247887.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.3352.1517875177.433385.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.3714.1517875179.128897.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.3791.1517875179.436805.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.4134.1517875181.277174.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.4373.1517875182.554858.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.4468.1517875183.20323.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.4843.1517875185.73985.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.4996.1517875185.888529.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.5087.1517875186.354925.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.5278.1517875187.330082.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.5543.1517875188.726955.dcm'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the bad actors... There are no mentions of these files in the annotations. \n",
    "# Do we treat these as a -1? or are these valid cases of the disorder... or drop them!\n",
    "sym_diff = train_names.symmetric_difference(unique_annotations)\n",
    "print(len(sym_diff))\n",
    "sym_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
